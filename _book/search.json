[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bringing genomics to the field",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "genomics_informed_provenancing.html#why-gd-and-gl",
    "href": "genomics_informed_provenancing.html#why-gd-and-gl",
    "title": "2  Genomic selection of sources",
    "section": "2.1 Why GD and GL?",
    "text": "2.1 Why GD and GL?"
  },
  {
    "objectID": "genomics_informed_provenancing.html#setting-up",
    "href": "genomics_informed_provenancing.html#setting-up",
    "title": "2  Genomic selection of sources",
    "section": "2.2 Setting up",
    "text": "2.2 Setting up\nRead in the necessary data for the source optimization. SnpEff v5.1 (Cingolani et al., 2012) was used to annotate genetic variants to functional class based on Norway spruce genome annotation.\n\n2.2.1 Import annotations from SnpEff\n\nlist &lt;- list.files(path = \"../../datashare/Spruce/exome_capture/WES_mapping/Annotations/ref_Pglauca/VCF_split_files\", \n                   pattern = \"Red_Spruce_intersect_poly_\", \n                   recursive=TRUE, full.names = T)\n\n# genes &lt;- lapply(list[1], function(x) read.table(x, nrow = 100000)) # originally run for testing\ngenes &lt;- lapply(list[1], function(x) read.table(x))\ncategory &lt;- lapply(genes, function(x) unlist(lapply(strsplit(as.character(x[,8]), split = \"|\", fixed = T), function(y) y[2])))\n\nTAB &lt;- genes[1:2]\nTAB &lt;- do.call(rbind, TAB)\ncategory &lt;- do.call(c, category)\n\nRead in the meta data for the samples\n\n# Info samples\nnames &lt;- unlist(lapply(strsplit(unlist(strsplit(as.character(read.table(\"all_bam.list\")[,1]), split = \"_rmdup.sorted.bam\")), split = \"./\"), function(x) x[2]))\npops &lt;- unlist(lapply(strsplit(names, split=\"_\"), function(x) x[1]))\n\ninfo_inds &lt;- read.table(\"./Info_samples_revised.txt\", header=T)\ninfo_inds &lt;- info_inds[match(as.character(names), as.character(info_inds$Family)),]\ninfo_pops &lt;- info_inds[!duplicated(info_inds$Site),-c(1,3,9,10)]\n\n\n\n2.2.2 Allele probabilities and frequencies\n\n# Read depth \ndepth &lt;- apply(TAB[,-c(1:9)], 2, function(x) as.integer(unlist(lapply(strsplit(as.character(x), split = \":\"), function(y) y[2]))))\n\n# Genotype probabilities, changed by NA for the uncovered sites \ngen_prob &lt;- apply(TAB[,-c(1:9)], 2, function(x) unlist(lapply(strsplit(as.character(x), split = \":\"), function(y) y[4])))\ngen_prob[which(depth==0)] &lt;- NA\n\n# Proba alternative allele\naltern_proba &lt;- apply(gen_prob, 2, function(x) (as.numeric(unlist(lapply(strsplit(as.character(x), split = \",\"), function(y) y[2])))+2*as.numeric(unlist(lapply(strsplit(as.character(x), split = \",\"), function(z) z[3]))))/2)\n\n# Frequency of the alternative allele for each locus and population\nTAB_pop &lt;- lapply(unique(pops),function(x) altern_proba[,which(pops==x)])\n\nnames(TAB_pop) &lt;- unique(pops)\n\nfreq_pop &lt;- lapply(TAB_pop, function(x) apply(x, 1, function(y) sum(y, na.rm = T)/sum(!is.na(y))))"
  },
  {
    "objectID": "genomics_informed_provenancing.html#functions-to-optimize-selection",
    "href": "genomics_informed_provenancing.html#functions-to-optimize-selection",
    "title": "2  Genomic selection of sources",
    "section": "2.3 Functions to optimize selection",
    "text": "2.3 Functions to optimize selection\n\n2.3.1 Select regions to select sources\nBased on the idea of Regional admixture provenancing (citation), seed sources were selected regionally for each restoration site. Three groups of source populations were subsetted for the three planting sites, removing XVC and HR because of their northern ancestry. More info on the regional ancestry detailed in (citation).\n\nOptimizing genetic diversityEstimate the genetic loadN Source selection\n\n\n\n# function to estimate allelic richness after rarefaction\nrarefy_AR &lt;- function(data, g, bootstraping=100){\n  Nijg &lt;- list()\n  Njg &lt;- g*2\n  nbind &lt;- ncol(data)\n  Nij &lt;- list()\n  for(boot in 1:bootstraping){\n    inds &lt;- sample(1:nbind, g, replace = FALSE)\n    if(g==1){\n      Nij[[boot]] &lt;- data[,inds]*2}\n    if(g&gt;1){\n      Nij[[boot]] &lt;- apply(data[,inds], 1, function(x) sum(x, na.rm = T)/sum(!is.na(x)))*g*2}\n  }\n  Nijg &lt;- rowMeans(do.call(cbind, Nij), na.rm = T)\n  Qijg &lt;- (Njg-Nijg)/Njg\n  Pijg &lt;- 1-Qijg\n  return(Pijg)\n}\n\n\n\nThe following function is used to estiamte the ratio of nonsynonymous/synonymous mutation based on the annotation from SnpEff v5.1 (Cingolani et al., 2012), which was used to annotate genetic variants to functional class based on Norway spruce genome annotation. The functional categories viz. missense variant, splice acceptor variant, splice donor variant, splice region variant, start lost, stop gained, stop lost were used to designate as non-synonymous mutation in our calculation for genetic load.\n\ngenetic_load &lt;- function(data, category){\n                nonsyn_sites &lt;- which(category==\"missense_variant\" | category==\"splice_acceptor_variant\" | category==\"splice_donor_variant\" | category==\"splice_region_variant\" | category==\"start_lost\" | category==\"stop_gained\" | category==\"stop_lost\")\n                freq_nonsyn &lt;- mean(data[nonsyn_sites], na.rm = T)\n                freq_syn &lt;- mean(data[-nonsyn_sites], na.rm = T)\n                ratio_2 &lt;- freq_nonsyn/freq_syn\n                return(ratio_2)\n}\n\n\n\nThis function combines the rarefy_AR and genetic_load function to estimate expected heterozygosity (Hexp), allelic richness and genetic load in all combinations of P populations. The P depends on the number of sources one decides to select for their restoration site.\n\n# function to estimate Hexp, Allelic Richness and Genetic Load in all combination of P populations\noptimize &lt;- function(data, P){\n  \n            # Total diversity and load with all the populations\n            TAB_tot &lt;- do.call(cbind,data)\n            freq_tot &lt;- apply(TAB_tot, 1, function(y) sum(y, na.rm = T)/sum(!is.na(y)))\n            hexp_tot &lt;- mean(2*freq_tot*(1-freq_tot), na.rm = T)\n            #all_rich_tot &lt;- mean(rarefy_AR(TAB_tot, ncol(TAB_tot)), na.rm = T)\n            genetic_load_tot &lt;- genetic_load(TAB_tot, category)\n            \n            # Genetic diversity and load with only a subset of P populations\n            hexp_sub &lt;- list()\n           \n            genetic_load_sub &lt;- list()\n            names &lt;- list()\n            comb &lt;- combn(1:length(data), P, simplify = F)\n            for(i in 1:length(comb)){\n              TAB_sub &lt;- do.call(cbind, data[comb[[i]]])\n              freq_sub &lt;- apply(TAB_sub, 1, function(y) sum(y, na.rm = T)/sum(!is.na(y)))\n              hexp_sub[i] &lt;- mean(2*freq_sub*(1-freq_sub), na.rm = T)\n              \n              genetic_load_sub[i] &lt;- genetic_load(TAB_sub, category)\n              names[i] &lt;- paste(names(data[comb[[i]]]), collapse=\"_\")\n            }\n            TAB_sub &lt;- do.call(rbind, lapply(1:length(hexp_sub), function(x) c(Hexp = hexp_sub[[x]], GenLoad = genetic_load_sub[[x]]))) #AllRich = all_rich_sub[[x]], \n            TAB &lt;- rbind(c(Hexp = hexp_tot, GenLoad = genetic_load_tot), TAB_sub) #AllRich = all_rich_tot, \n            rownames(TAB) &lt;- c(\"total\", unlist(names))\n            \n            return(TAB)\n}\n\n\n\n\n\n\n2.3.2 Apply the function to get optimal source combinations\n\n# Optimization sources for site in Maryland\nres_maryland &lt;- optimize(TAB_pop_maryland, 3)\nwhich.max(res_maryland[-1,1]/res_maryland[-1,2])\nres_maryland[c(1,which.max(res_maryland[-1,1]/res_maryland[-1,2])+1),]\n\n# Optimization sources for site in West Virginia\nres_westvirginia_4 &lt;- optimize(TAB_pop_westvirginia, 4)\nwhich.max(res_westvirginia_4[-1,1]/res_westvirginia_4[-1,2])\n\n# Optimization sources for site in Virginia\nres_virginia_4 &lt;- optimize(TAB_pop_virginia, 4)\nwhich.max(res_virginia_4[-1,1]/res_virginia_4[-1,2])"
  },
  {
    "objectID": "genomics_informed_provenancing.html#factors-affecting-source-selection",
    "href": "genomics_informed_provenancing.html#factors-affecting-source-selection",
    "title": "2  Genomic selection of sources",
    "section": "2.4 Factors affecting source selection",
    "text": "2.4 Factors affecting source selection"
  },
  {
    "objectID": "genomics_informed_provenancing.html#saving-data-for-downstream-analysis",
    "href": "genomics_informed_provenancing.html#saving-data-for-downstream-analysis",
    "title": "2  Genomic selection of sources",
    "section": "2.5 Saving data for downstream analysis",
    "text": "2.5 Saving data for downstream analysis"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  }
]